"C:\Program Files\Java\jdk-14.0.2\bin\java.exe" -ea -Didea.test.cyclic.buffer.size=1048576 "-javaagent:C:\Program Files\JetBrains\IntelliJ IDEA Community Edition 2020.2\lib\idea_rt.jar=65125:C:\Program Files\JetBrains\IntelliJ IDEA Community Edition 2020.2\bin" -Dfile.encoding=UTF-8 -classpath "C:\Program Files\JetBrains\IntelliJ IDEA Community Edition 2020.2\lib\idea_rt.jar;C:\Program Files\JetBrains\IntelliJ IDEA Community Edition 2020.2\plugins\junit\lib\junit5-rt.jar;C:\Program Files\JetBrains\IntelliJ IDEA Community Edition 2020.2\plugins\junit\lib\junit-rt.jar;C:\Users\wolfgang\Documents\GitHub\GBG\bin;C:\Users\wolfgang\Documents\GitHub\GBG\lib\jfreechart-1.0.17\jcommon-1.0.21.jar;C:\Users\wolfgang\Documents\GitHub\GBG\lib\jfreechart-1.0.17\jfreechart-1.0.17.jar;C:\Users\wolfgang\Documents\GitHub\GBG\lib\commons-math3-3.6.1.jar;C:\Users\wolfgang\Documents\GitHub\GBG\lib\cmaes.jar;C:\Users\wolfgang\Documents\GitHub\GBG\lib\commons-compress-1.9\commons-compress-1.9.jar;C:\Users\wolfgang\.m2\repository\org\junit\jupiter\junit-jupiter\5.4.2\junit-jupiter-5.4.2.jar;C:\Users\wolfgang\.m2\repository\org\junit\jupiter\junit-jupiter-api\5.4.2\junit-jupiter-api-5.4.2.jar;C:\Users\wolfgang\.m2\repository\org\apiguardian\apiguardian-api\1.0.0\apiguardian-api-1.0.0.jar;C:\Users\wolfgang\.m2\repository\org\opentest4j\opentest4j\1.1.1\opentest4j-1.1.1.jar;C:\Users\wolfgang\.m2\repository\org\junit\platform\junit-platform-commons\1.4.2\junit-platform-commons-1.4.2.jar;C:\Users\wolfgang\.m2\repository\org\junit\jupiter\junit-jupiter-params\5.4.2\junit-jupiter-params-5.4.2.jar;C:\Users\wolfgang\.m2\repository\org\junit\jupiter\junit-jupiter-engine\5.4.2\junit-jupiter-engine-5.4.2.jar;C:\Users\wolfgang\.m2\repository\org\junit\platform\junit-platform-engine\1.4.2\junit-platform-engine-1.4.2.jar;C:\Users\wolfgang\.m2\repository\org\jetbrains\annotations\19.0.0\annotations-19.0.0.jar;C:\Users\wolfgang\Documents\GitHub\GBG\lib\junit-runners-1.3.jar;C:\Users\wolfgang\.m2\repository\junit\junit\4.12\junit-4.12.jar;C:\Users\wolfgang\.m2\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;C:\Users\wolfgang\.m2\repository\org\testng\testng\6.14.3\testng-6.14.3.jar;C:\Users\wolfgang\.m2\repository\com\beust\jcommander\1.72\jcommander-1.72.jar;C:\Users\wolfgang\.m2\repository\org\apache-extras\beanshell\bsh\2.0b6\bsh-2.0b6.jar;C:\Users\wolfgang\Documents\GitHub\GBG\lib\Ludii-1.3.0.jar;C:\Users\wolfgang\Documents\GitHub\GBG\lib\guava-31.0.1-jre.jar" com.intellij.rt.junit.JUnitStarter -ideVersion5 -junit4 games.Othello.TestMain,sweepOthelloEvalTest
Training duration: 6092.281 sec
Eval for training: 1350.871 sec
[NTuple4ValueFunc.weightAnalysis] TDNTuple4Agt (3276800 weights, 1667405 active (51%)): 
             per       LUT    
   Quantile [000] = -0.0937932
   Quantile [025] = -0.0001504
   Quantile [050] = -0.0000108
   Quantile [075] = +0.0000590
   Quantile [100] = +0.0669347
[Arena.loadAgent] Agent TD-Ntuple-4 successfully loaded from agents/Othello/TCL4-100_7_250k-lam05_P4_nPly2-FAm_A.agt.zip!
creating edax2
Competition, 1 episodes: 
      X: TD-Ntuple-4[iter=1000] 
   vs O: Edax2: depth:0, moveTime:10.0
0: X wins
# Black = 53, # White = 11
Avg ScoreTuple for all players:    (1,000, -1,000)
Avg # moves in 1 episodes = 60,000
EPS=1.0E-8, iter=1000, dEdax=0, p=0, winrate=1.0
Competition, 1 episodes: 
      X: Edax2: depth:0, moveTime:10.0 
   vs O: TD-Ntuple-4[iter=1000]
0: O wins
# Black = 5, # White = 59
Avg ScoreTuple for all players:    (-1,000, 1,000)
Avg # moves in 1 episodes = 60,000
EPS=1.0E-8, iter=1000, dEdax=0, p=1, winrate=1.0
Results written to test_EWN_branch.csv
[quickOthelloEval,TCL4-100_7_250k-lam05_P4_nPly2-FAm_A.agt.zip] all done.
Training duration: 6092.281 sec
Eval for training: 1350.871 sec
[NTuple4ValueFunc.weightAnalysis] TDNTuple4Agt (3276800 weights, 1667405 active (51%)): 
             per       LUT    
   Quantile [000] = -0.0937932
   Quantile [025] = -0.0001504
   Quantile [050] = -0.0000108
   Quantile [075] = +0.0000590
   Quantile [100] = +0.0669347
[Arena.loadAgent] Agent TD-Ntuple-4 successfully loaded from agents/Othello/TCL4-100_7_250k-lam05_P4_nPly2-FAm_A.agt.zip!
creating edax2
Competition, 1 episodes: 
      X: TD-Ntuple-4[iter=1000] 
   vs O: Edax2: depth:1, moveTime:10.0
0: X wins
# Black = 55, # White = 9
Avg ScoreTuple for all players:    (1,000, -1,000)
Avg # moves in 1 episodes = 60,000
EPS=1.0E-8, iter=1000, dEdax=1, p=0, winrate=1.0
Competition, 1 episodes: 
      X: Edax2: depth:1, moveTime:10.0 
   vs O: TD-Ntuple-4[iter=1000]
0: O wins
# Black = 1, # White = 55
Avg ScoreTuple for all players:    (-1,000, 1,000)
Avg # moves in 1 episodes = 52,000
EPS=1.0E-8, iter=1000, dEdax=1, p=1, winrate=1.0
Results written to test_EWN_branch.csv
[quickOthelloEval,TCL4-100_7_250k-lam05_P4_nPly2-FAm_A.agt.zip] all done.
Training duration: 6092.281 sec
Eval for training: 1350.871 sec
[NTuple4ValueFunc.weightAnalysis] TDNTuple4Agt (3276800 weights, 1667405 active (51%)): 
             per       LUT    
   Quantile [000] = -0.0937932
   Quantile [025] = -0.0001504
   Quantile [050] = -0.0000108
   Quantile [075] = +0.0000590
   Quantile [100] = +0.0669347
[Arena.loadAgent] Agent TD-Ntuple-4 successfully loaded from agents/Othello/TCL4-100_7_250k-lam05_P4_nPly2-FAm_A.agt.zip!
creating edax2
Competition, 1 episodes: 
      X: TD-Ntuple-4[iter=1000] 
   vs O: Edax2: depth:2, moveTime:10.0
0: X wins
# Black = 55, # White = 9
Avg ScoreTuple for all players:    (1,000, -1,000)
Avg # moves in 1 episodes = 60,000
EPS=1.0E-8, iter=1000, dEdax=2, p=0, winrate=1.0
Competition, 1 episodes: 
      X: Edax2: depth:2, moveTime:10.0 
   vs O: TD-Ntuple-4[iter=1000]
0: O wins
# Black = 14, # White = 50
Avg ScoreTuple for all players:    (-1,000, 1,000)
Avg # moves in 1 episodes = 60,000
EPS=1.0E-8, iter=1000, dEdax=2, p=1, winrate=1.0
Results written to test_EWN_branch.csv
[quickOthelloEval,TCL4-100_7_250k-lam05_P4_nPly2-FAm_A.agt.zip] all done.
Training duration: 6092.281 sec
Eval for training: 1350.871 sec
[NTuple4ValueFunc.weightAnalysis] TDNTuple4Agt (3276800 weights, 1667405 active (51%)): 
             per       LUT    
   Quantile [000] = -0.0937932
   Quantile [025] = -0.0001504
   Quantile [050] = -0.0000108
   Quantile [075] = +0.0000590
   Quantile [100] = +0.0669347
[Arena.loadAgent] Agent TD-Ntuple-4 successfully loaded from agents/Othello/TCL4-100_7_250k-lam05_P4_nPly2-FAm_A.agt.zip!
creating edax2
Competition, 1 episodes: 
      X: TD-Ntuple-4[iter=1000] 
   vs O: Edax2: depth:3, moveTime:10.0
0: X wins
# Black = 39, # White = 25
Avg ScoreTuple for all players:    (1,000, -1,000)
Avg # moves in 1 episodes = 60,000
EPS=1.0E-8, iter=1000, dEdax=3, p=0, winrate=1.0
Competition, 1 episodes: 
      X: Edax2: depth:3, moveTime:10.0 
   vs O: TD-Ntuple-4[iter=1000]
0: O wins
# Black = 28, # White = 36
Avg ScoreTuple for all players:    (-1,000, 1,000)
Avg # moves in 1 episodes = 60,000
EPS=1.0E-8, iter=1000, dEdax=3, p=1, winrate=1.0
Results written to test_EWN_branch.csv
[quickOthelloEval,TCL4-100_7_250k-lam05_P4_nPly2-FAm_A.agt.zip] all done.
Training duration: 6092.281 sec
Eval for training: 1350.871 sec
[NTuple4ValueFunc.weightAnalysis] TDNTuple4Agt (3276800 weights, 1667405 active (51%)): 
             per       LUT    
   Quantile [000] = -0.0937932
   Quantile [025] = -0.0001504
   Quantile [050] = -0.0000108
   Quantile [075] = +0.0000590
   Quantile [100] = +0.0669347
[Arena.loadAgent] Agent TD-Ntuple-4 successfully loaded from agents/Othello/TCL4-100_7_250k-lam05_P4_nPly2-FAm_A.agt.zip!
creating edax2
Competition, 1 episodes: 
      X: TD-Ntuple-4[iter=1000] 
   vs O: Edax2: depth:4, moveTime:10.0
0: X wins
# Black = 42, # White = 22
Avg ScoreTuple for all players:    (1,000, -1,000)
Avg # moves in 1 episodes = 60,000
EPS=1.0E-8, iter=1000, dEdax=4, p=0, winrate=1.0
Competition, 1 episodes: 
      X: Edax2: depth:4, moveTime:10.0 
   vs O: TD-Ntuple-4[iter=1000]
0: X wins
# Black = 37, # White = 27
Avg ScoreTuple for all players:    (1,000, -1,000)
Avg # moves in 1 episodes = 60,000
EPS=1.0E-8, iter=1000, dEdax=4, p=1, winrate=0.0
Results written to test_EWN_branch.csv
[quickOthelloEval,TCL4-100_7_250k-lam05_P4_nPly2-FAm_A.agt.zip] all done.
Training duration: 6092.281 sec
Eval for training: 1350.871 sec
[NTuple4ValueFunc.weightAnalysis] TDNTuple4Agt (3276800 weights, 1667405 active (51%)): 
             per       LUT    
   Quantile [000] = -0.0937932
   Quantile [025] = -0.0001504
   Quantile [050] = -0.0000108
   Quantile [075] = +0.0000590
   Quantile [100] = +0.0669347
[Arena.loadAgent] Agent TD-Ntuple-4 successfully loaded from agents/Othello/TCL4-100_7_250k-lam05_P4_nPly2-FAm_A.agt.zip!
creating edax2
Competition, 1 episodes: 
      X: TD-Ntuple-4[iter=1000] 
   vs O: Edax2: depth:5, moveTime:10.0
0: X wins
# Black = 34, # White = 30
Avg ScoreTuple for all players:    (1,000, -1,000)
Avg # moves in 1 episodes = 60,000
EPS=1.0E-8, iter=1000, dEdax=5, p=0, winrate=1.0
Competition, 1 episodes: 
      X: Edax2: depth:5, moveTime:10.0 
   vs O: TD-Ntuple-4[iter=1000]
0: X wins
# Black = 34, # White = 30
Avg ScoreTuple for all players:    (1,000, -1,000)
Avg # moves in 1 episodes = 60,000
EPS=1.0E-8, iter=1000, dEdax=5, p=1, winrate=0.0
Results written to test_EWN_branch.csv
[quickOthelloEval,TCL4-100_7_250k-lam05_P4_nPly2-FAm_A.agt.zip] all done.
Training duration: 6092.281 sec
Eval for training: 1350.871 sec
[NTuple4ValueFunc.weightAnalysis] TDNTuple4Agt (3276800 weights, 1667405 active (51%)): 
             per       LUT    
   Quantile [000] = -0.0937932
   Quantile [025] = -0.0001504
   Quantile [050] = -0.0000108
   Quantile [075] = +0.0000590
   Quantile [100] = +0.0669347
[Arena.loadAgent] Agent TD-Ntuple-4 successfully loaded from agents/Othello/TCL4-100_7_250k-lam05_P4_nPly2-FAm_A.agt.zip!
creating edax2
Competition, 1 episodes: 
      X: TD-Ntuple-4[iter=1000] 
   vs O: Edax2: depth:6, moveTime:10.0
0: X wins
# Black = 36, # White = 28
Avg ScoreTuple for all players:    (1,000, -1,000)
Avg # moves in 1 episodes = 60,000
EPS=1.0E-8, iter=1000, dEdax=6, p=0, winrate=1.0
Competition, 1 episodes: 
      X: Edax2: depth:6, moveTime:10.0 
   vs O: TD-Ntuple-4[iter=1000]
0: X wins
# Black = 40, # White = 24
Avg ScoreTuple for all players:    (1,000, -1,000)
Avg # moves in 1 episodes = 60,000
EPS=1.0E-8, iter=1000, dEdax=6, p=1, winrate=0.0
Results written to test_EWN_branch.csv
[quickOthelloEval,TCL4-100_7_250k-lam05_P4_nPly2-FAm_A.agt.zip] all done.
Training duration: 6092.281 sec
Eval for training: 1350.871 sec
[NTuple4ValueFunc.weightAnalysis] TDNTuple4Agt (3276800 weights, 1667405 active (51%)): 
             per       LUT    
   Quantile [000] = -0.0937932
   Quantile [025] = -0.0001504
   Quantile [050] = -0.0000108
   Quantile [075] = +0.0000590
   Quantile [100] = +0.0669347
[Arena.loadAgent] Agent TD-Ntuple-4 successfully loaded from agents/Othello/TCL4-100_7_250k-lam05_P4_nPly2-FAm_A.agt.zip!
creating edax2
Competition, 1 episodes: 
      X: TD-Ntuple-4[iter=1000] 
   vs O: Edax2: depth:7, moveTime:10.0
0: O wins
# Black = 20, # White = 44
Avg ScoreTuple for all players:    (-1,000, 1,000)
Avg # moves in 1 episodes = 60,000
EPS=1.0E-8, iter=1000, dEdax=7, p=0, winrate=0.0
Competition, 1 episodes: 
      X: Edax2: depth:7, moveTime:10.0 
   vs O: TD-Ntuple-4[iter=1000]
0: X wins
# Black = 38, # White = 26
Avg ScoreTuple for all players:    (1,000, -1,000)
Avg # moves in 1 episodes = 60,000
EPS=1.0E-8, iter=1000, dEdax=7, p=1, winrate=0.0
Results written to test_EWN_branch.csv
[quickOthelloEval,TCL4-100_7_250k-lam05_P4_nPly2-FAm_A.agt.zip] all done.
Training duration: 6092.281 sec
Eval for training: 1350.871 sec
[NTuple4ValueFunc.weightAnalysis] TDNTuple4Agt (3276800 weights, 1667405 active (51%)): 
             per       LUT    
   Quantile [000] = -0.0937932
   Quantile [025] = -0.0001504
   Quantile [050] = -0.0000108
   Quantile [075] = +0.0000590
   Quantile [100] = +0.0669347
[Arena.loadAgent] Agent TD-Ntuple-4 successfully loaded from agents/Othello/TCL4-100_7_250k-lam05_P4_nPly2-FAm_A.agt.zip!
creating edax2
Competition, 1 episodes: 
      X: TD-Ntuple-4[iter=1000] 
   vs O: Edax2: depth:8, moveTime:10.0
0: O wins
# Black = 19, # White = 45
Avg ScoreTuple for all players:    (-1,000, 1,000)
Avg # moves in 1 episodes = 60,000
EPS=1.0E-8, iter=1000, dEdax=8, p=0, winrate=0.0
Competition, 1 episodes: 
      X: Edax2: depth:8, moveTime:10.0 
   vs O: TD-Ntuple-4[iter=1000]
0: X wins
# Black = 37, # White = 27
Avg ScoreTuple for all players:    (1,000, -1,000)
Avg # moves in 1 episodes = 60,000
EPS=1.0E-8, iter=1000, dEdax=8, p=1, winrate=0.0
Results written to test_EWN_branch.csv
[quickOthelloEval,TCL4-100_7_250k-lam05_P4_nPly2-FAm_A.agt.zip] all done.
quickEvalTest finished in 148.443 sec.

Process finished with exit code 0
